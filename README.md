# Titanic Data Preprocessing and Feature Engineering

This repository contains a Jupyter Notebook (`skillcraft-2 (1).ipynb`) detailing the **data cleaning, feature engineering, and preparation steps** performed on a sample of the Titanic dataset, ready for a machine learning model.

## üõ†Ô∏è Data Cleaning & Handling Missing Values

The notebook addresses missing values and performs data cleaning as follows:

* **Initial Data Check:** Identified missing values in the **Age** and **Cabin** columns, as well as potential missing values in **Embarked**.
    *  (This visualization is generated by `missingno.matrix(df)` in the notebook.)

* **Imputation:**
    * **Age:** Missing values were filled using the **median age**.
    * **Embarked:** Missing values were filled using the **mode** (most frequent value).
    * **Cabin:** The original `Cabin` column was dropped after creating a new binary feature, `HasCabin`.

## ‚öôÔ∏è Feature Engineering

Several new features were created from the existing data to improve model performance:

| Feature | Source Column(s) | Description |
| :--- | :--- | :--- |
| **HasCabin** | `Cabin` | Binary flag (0 or 1) indicating if the passenger had a cabin recorded. |
| **Title** | `Name` | Extracted the title (e.g., 'Mr', 'Miss') from the `Name` column. Rare titles were grouped into 'Other'. |
| **FamilySize** | `SibSp` + `Parch` | Calculated as the sum of siblings/spouses (`SibSp`), parents/children (`Parch`), plus 1 (for the passenger themselves). |
| **AgeBin** | `Age` | Categorized age into bins: 'Child', 'Teen', 'Adult', 'Middle', 'Senior'. |
| **Fare\_log** | `Fare` | A log-transformed version of `Fare` to normalize its distribution. |

The notebook also includes a visualization of **Survival Rate by Title**:
* 
## üß™ Model Preparation

* **Encoding:** Categorical features (`Pclass`, `Sex`, `AgeBin`, `Title`, `Embarked`) were converted into **dummy/one-hot encoded** numerical columns using `pd.get_dummies()`.
* **Train-Test Split:** The final feature set (`X`) and the target variable (`y` = `Survived`) were split into training and testing sets for model development using `sklearn.model_selection.train_test_split`.
* **Output:** The final processed DataFrame is saved to `titanic_cleaned.csv`.